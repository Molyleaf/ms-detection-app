# convert.py
import pandas as pd
import numpy as np
import joblib
import os
import re
from core.pipeline import MS1Cleaner

def parse_ms_string(ms_str):
    """å°† mz:int,mz:int æ ¼å¼çš„å­—ç¬¦ä¸²è§£æä¸º (mz_arr, int_arr)"""
    try:
        peaks = [p.split(':') for p in str(ms_str).replace(';', ',').split(',') if ':' in p]
        if not peaks: return np.array([]), np.array([])
        mzs = np.array([float(p[0]) for p in peaks])
        ints = np.array([float(p[1]) for p in peaks])
        return mzs, ints
    except:
        return np.array([]), np.array([])

def clean_spectrum(mzs, ints):
    """æ‰§è¡Œä¸ Notebook ä¸€è‡´çš„äºŒçº§è´¨è°±æ¸…æ´—é€»è¾‘ï¼šå½’ä¸€åŒ– -> åŒä½ç´ æ¸…æ´— -> å¼ºåº¦è¿‡æ»¤"""
    if len(mzs) == 0: return mzs, ints

    # 1. å½’ä¸€åŒ– (0-100)
    max_i = np.max(ints)
    if max_i > 0:
        ints = (ints / max_i) * 100.0

    # 2. è´ªå©ªåŒä½ç´ æ¸…æ´— (2Da)
    # æŒ‰å¼ºåº¦é™åºæ’åˆ—è¿›è¡ŒæŠ‘åˆ¶
    sort_idx = np.argsort(ints)[::-1]
    mzs_s, ints_s = mzs[sort_idx], ints[sort_idx]

    keep = np.ones(len(mzs_s), dtype=bool)
    for i in range(len(mzs_s)):
        if not keep[i]: continue
        for j in range(i + 1, len(mzs_s)):
            if keep[j] and abs(mzs_s[j] - mzs_s[i]) <= 2.0:
                keep[j] = False

    # 3. è¿‡æ»¤å¼ºåº¦ < 1.0 ä¸”æ¢å¤è´¨é‡æ’åº
    final_mzs = mzs_s[keep]
    final_ints = ints_s[keep]

    mask = final_ints >= 1.0
    final_mzs, final_ints = final_mzs[mask], final_ints[mask]

    order = np.argsort(final_mzs)
    return final_mzs[order], final_ints[order]

def save_risk_db(excel_path='../data/risk_matching-1.xlsx', output_path='data_processed/risk_db.joblib'):
    """é¢„å¤„ç†é£é™©æ•°æ®åº“ï¼šæå–å„çº§é£é™© Mass å¹¶è½¬æ¢ä¸ºé›†åˆæˆ–åˆ—è¡¨"""
    print(f"æ­£åœ¨è½¬æ¢é£é™©åº“: {excel_path}...")
    if not os.path.exists(excel_path):
        print("âŒ æœªæ‰¾åˆ°é£é™©åº“æ–‡ä»¶")
        return

    # å®šä¹‰æ¨¡å¼æ˜ å°„ (æ ¹æ® Notebook é€»è¾‘)
    db = {'positive': {}, 'negative': {}}

    # å‡è®¾ Excel ä¸­é€šè¿‡ Sheet æˆ–åˆ—åŒºåˆ†æ­£è´Ÿç¦»å­ï¼Œæ­¤å¤„æ¼”ç¤ºæ ‡å‡†é€»è¾‘
    xls = pd.ExcelFile(excel_path)
    # æ˜ å°„é€»è¾‘ï¼šRisk0 å’Œ Risk1 Precise ä½¿ç”¨åˆ—è¡¨ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰ï¼Œå…¶ä½™ä½¿ç”¨ round(2) é›†åˆï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
    sheet_map = {
        'é£é™©0': 'risk0',
        'é£é™©1': 'risk1',
        'é£é™©2': 'risk2',
        'é£é™©3': 'risk3'
    }

    for mode in ['positive', 'negative']:
        mode_data = {}
        for sheet_name, key in sheet_map.items():
            if sheet_name in xls.sheet_names:
                df = pd.read_excel(xls, sheet_name=sheet_name)
                if 'Mass' in df.columns:
                    masses = df['Mass'].dropna().tolist()
                    if key == 'risk0':
                        mode_data['risk0'] = masses
                    elif key == 'risk1':
                        mode_data['risk1_precise'] = masses
                        mode_data['risk1_rounded'] = set(round(m, 2) for m in masses)
                    else:
                        mode_data[key] = set(round(m, 2) for m in masses)
        db[mode] = mode_data

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    joblib.dump(db, output_path)
    print(f"âœ… é£é™©åº“å·²ä¿å­˜è‡³: {output_path}")

def save_spectrum_db(training_data_path='../data/åŒ–åˆç‰©-7.xlsx', output_path='data_processed/spectrum_db.joblib'):
    """é¢„å¤„ç†åŒ–åˆç‰©äºŒçº§è´¨è°±åº“ï¼šè§£æã€æ¸…æ´—å¹¶å­˜å‚¨ä¸ºé«˜æ•ˆåˆ—è¡¨"""
    print(f"æ­£åœ¨è½¬æ¢è´¨è°±åº“: {training_data_path}...")
    if not os.path.exists(training_data_path):
        print("âŒ æœªæ‰¾åˆ°åŒ–åˆç‰©æ•°æ®åº“")
        return

    df = pd.read_excel(training_data_path)
    library = []

    for i, row in df.iterrows():
        ms_str = str(row.get('MS', ''))
        mzs, ints = parse_ms_string(ms_str)

        # ä¸¥æ ¼æ‰§è¡Œ Notebook çš„æ¸…æ´—é€»è¾‘
        clean_mzs, clean_ints = clean_spectrum(mzs, ints)

        if len(clean_mzs) > 0:
            library.append({
                'id': i,
                'name': str(row.get('Name', f'Unknown_{i}')),
                'smiles': str(row.get('SMILES', 'N/A')),
                'mz': clean_mzs,
                'intensities': clean_ints
            })

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    joblib.dump(library, output_path)
    print(f"âœ… è´¨è°±åº“å·²ä¿å­˜ (å…± {len(library)} ä¸ªæ¡ç›®) -> {output_path}")

def save_global_stats(training_data_path='../data/åŒ–åˆç‰©-7.xlsx', output_path='data_processed/stats.joblib'):
    """ä»è®­ç»ƒé›†æå– MZ ç»Ÿè®¡é‡ï¼Œç¡®ä¿ä¸ MS2GraphExtractor é€»è¾‘ä¸€è‡´"""
    print("æ­£åœ¨ç”Ÿæˆç»Ÿè®¡é‡ (stats.joblib)...")
    df = pd.read_excel(training_data_path)
    all_mz = []
    all_max_intensity_mz = []

    for _, row in df.iterrows():
        mzs, ints = parse_ms_string(row.get('MS', ''))
        if len(mzs) == 0: continue

        all_mz.extend(mzs)
        all_max_intensity_mz.append(mzs[np.argmax(ints)])

    stats = {
        'mz_mean': float(np.mean(all_mz)),
        'mz_std': float(np.std(all_mz)),
        'max_intensity_mz_mean': float(np.mean(all_max_intensity_mz)),
        'max_intensity_mz_std': float(np.std(all_max_intensity_mz))
    }

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    joblib.dump(stats, output_path)
    print(f"âœ… ç»Ÿè®¡é‡å·²æ›´æ–°: {stats}")

def convert_txt_to_xlsx(txt_path):
    """è¾…åŠ©åŠŸèƒ½ï¼šå°†å¸¸è§çš„æ–‡æœ¬æ ¼å¼è´¨è°±æ•°æ®è½¬ä¸ºæ ‡å‡†çš„ Excel æ ¼å¼"""
    # è¯†åˆ«å¸¸è§çš„æ–‡æœ¬åˆ†éš”ç¬¦ï¼ˆç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€é€—å·ï¼‰
    try:
        df = pd.read_csv(txt_path, sep=r'\s+|,', engine='python', names=['Mass', 'Intensity'])
        output_xlsx = txt_path.rsplit('.', 1)[0] + '.xlsx'
        df.to_excel(output_xlsx, index=False)
        print(f"å·²å°† {txt_path} è½¬æ¢ä¸º {output_xlsx}")
        return output_xlsx
    except Exception as e:
        print(f"è½¬æ¢ {txt_path} å¤±è´¥: {e}")
        return None

if __name__ == '__main__':
    # ç¡®ä¿è¿è¡Œç¯å¢ƒç›®å½•å­˜åœ¨
    os.makedirs('data_processed', exist_ok=True)

    # 1. è½¬æ¢é£é™©åº“ (L1åŒ¹é…ç”¨)
    save_risk_db('../data/risk_matching-1.xlsx')

    # 2. è½¬æ¢è´¨è°±åº“ (L2å›æº¯åŒ¹é…ç”¨)
    save_spectrum_db('../data/åŒ–åˆç‰©-7.xlsx')

    # 3. ç”Ÿæˆç‰¹å¾å·¥ç¨‹ç»Ÿè®¡é‡ (æ¨¡å‹æ¨ç†ç”¨)
    save_global_stats('../data/åŒ–åˆç‰©-7.xlsx')

    print("\nğŸš€ æ‰€æœ‰æ•°æ®å·²è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ¼å¼ã€‚")